Preguntas:

Process.cpp:

	min_object_pixels
	 1 |1,20|1,05
	-------------
	1,1|1,25|1,15

propuesto por sutter. Dependiendo en que posicion esta priorizar la señalización. 



normalizeMat():

   (xi-min)
1 - ---------
   (max-min)

detection():

	El threshold que se aplica a la imagen original de profundidad (depths_ocv), de 130, es para eliminar objetos mas lejandos que no nos importan? A que distancia se corresponde esta valor? Se puede configurar desde el archivo de configurar parametros?

	Adaptative threshold: nos permite hacer una primera estimiacion de entre que es suelo y que no es suelo, que luego convinado con las normales tendremos la segmentación final de que suelo. Tiene sentido hacerlo con el mismo threshold que el anterior?
De esta manera nos  permite disintguir obstaculos negativos longitudinales como hablabamos en la reunión pasada.

floor_depth: el nombre de la variable puede llevar a confusión al principio porque no se tiene en cuenta la depth a la hora de identificar el suelo. Porque se hace floor_depth-red_chn (red_chn = R-(G+B))?


stepDetection():

	Porque teneis calculado el v-disparity para orig_depths y para floor_depth?
	orig_depths: imagen completa y original de profundidad [0,255]
	floor_depth: imagen de profundidad de las zonas que se considera suelo (Y normal --> threshold 100 --> -Red_chnl)

	Se ha probado a usar la imagen de depth del suelo sacado del green_chn (lo que se considera suelo teniendo en cuenta las normales y el la disparidad)?


	Porque se calcula el v-hist de la mitad de la imagen? No tenemos ya identificado lo que es suelo?

	Que hace esta linea de codigo? 
	vhist_floor.row(i) = tmpHistMat_floor.t() / (float) depth_roi_floor.rows / 2;

	Para definir si es un escalon o no, es mirar si en un salto de 5 lineas de pixeles haya un salto en la disparidad mayor a 5 y menor a 200? Porque estos valores? 
prev_pos - pos)>min_diff && (prev_pos - pos)<200

IMU:
Todas las divisiones que se hacen 

---------------------------------------------------------------------------------------------

Por qué el histograma de vhist se hace solamente de la mitad del ROI?

Preguntar sobre los problemas para hacer ir la el programa en el portatil
-----------------------------------------------------------------------------------------------
MaxDiff():
Por cada v-hist solo se puede encontrar un escalon? La variable max_pos no se guarda cada vez, solo guarda el últimno valor.
Si es porque solo queremos detectar un escalon y  el que este mas cerca del usuario, entonces porque no iteramos el v-hist por abajo en vez de por la mitad?
Además de guardar la row en que se encuentra el escalón, no guardamos la column porque solamente estamos cogiendo el tercio central inferior no? 
------------------------------------------------------------------------------------------------
Detection():
Loop over the image in a row major for stairs and hole detection. Porque para stairs and row detection?

-------------------------------------------------------------------------------------------------
Cual es el frame rate para el procesamiento? Es independiente al frame rate al que ve el usuario por las gafas?

[seguimiento pregunta anterior] En el floor_depth Continuamos haciendo la resta aqui?

Cambiar localización de cuadro (min distance, threshold ...) de texto durante la visualización.

La distáncia maxima de detección tiene limite?

Necesitamos tanta resolución de la imagen para hacer la detección? Entiendo que para la visualización del usuario sí, pero a la hora de hacer el procesado, no deberiamos bajar esta resolución o coger menos pixeles (parámetro/Variable global)?

El valor que da la camara respecto a la depth, esta normalizado en cada imagen? o es absoluto? 
Como lo tratais vosotros luego?
No existe una funcion del opencv que normalize una matriz? Será seguramente más eficiente que nuestra función.

Podemos añadir un modo debug para los escalones? podriamos añadir linea donde hay detección.

Como se hace la detección de escalones laterales, y como se señalizan.

Porque pintamos los pixeles cuando no estamos en el modo depuración (modo 'p')? En teoria ya tenemos hecha la segmentación del suelo.

De la misma manera que le pregunta anterior, para que sirve la variable green_chn? es solamente para visualización? entonces porque no usamos variable floor_chn?

Que pasa cuando se bajan los fps de el main.cpp?

Explicar cambios de ratios en la detección de escalones laterales hechos por Jaume. Esto aumenta la detección de escalones frontales sin augmentar los falsos positivos.

En la detección de escalones frontales, si la disparidad curva de la disparidad va hacia la derecha por algún fallo de imagen, es descartada?

Es dificil añadir un boton de pausa, cuando se ejecuta la aplicación cargando un arhivo SVO?

El video SVO cuando es ejecutado con el programa va a una velocidad mayor que cuando se grabó. Es porque los fps de grabación fueron más bajos que los de captación del algoritmo?

--------------------------------------------------------------------------------------

Si se normaliza los valores para que siempre estemos en la misma escala de profundidad, el threshold de 130 de la mitad superior de la imagen antes del adaptative threshold siempre eliminará valores más alla de 390cm.
Entonces, si tenemos puesto aquí este limite y en la función de normalización tenemos el limite de 768cm, cual es el valor correcto? Y entonces que se le permite ajustar al usuario?

